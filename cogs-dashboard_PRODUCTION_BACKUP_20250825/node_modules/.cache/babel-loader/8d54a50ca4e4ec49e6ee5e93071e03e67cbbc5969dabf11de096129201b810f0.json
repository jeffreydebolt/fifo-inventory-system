{"ast":null,"code":"import { timestampInSeconds } from '@sentry/utils';\nimport { DEFAULT_FLUSH_INTERVAL, SET_METRIC_TYPE, MAX_WEIGHT } from './constants.js';\nimport { METRIC_MAP } from './instance.js';\nimport { updateMetricSummaryOnActiveSpan } from './metric-summary.js';\nimport { sanitizeMetricKey, sanitizeTags, sanitizeUnit, getBucketKey } from './utils.js';\n\n/**\n * A metrics aggregator that aggregates metrics in memory and flushes them periodically.\n */\nclass MetricsAggregator {\n  // TODO(@anonrig): Use FinalizationRegistry to have a proper way of flushing the buckets\n  // when the aggregator is garbage collected.\n  // Ref: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/FinalizationRegistry\n\n  // Different metrics have different weights. We use this to limit the number of metrics\n  // that we store in memory.\n\n  // Cast to any so that it can use Node.js timeout\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n\n  // SDKs are required to shift the flush interval by random() * rollup_in_seconds.\n  // That shift is determined once per startup to create jittering.\n\n  // An SDK is required to perform force flushing ahead of scheduled time if the memory\n  // pressure is too high. There is no rule for this other than that SDKs should be tracking\n  // abstract aggregation complexity (eg: a counter only carries a single float, whereas a\n  // distribution is a float per emission).\n  //\n  // Force flush is used on either shutdown, flush() or when we exceed the max weight.\n\n  constructor(_client) {\n    this._client = _client;\n    this._buckets = new Map();\n    this._bucketsTotalWeight = 0;\n    this._interval = setInterval(() => this._flush(), DEFAULT_FLUSH_INTERVAL);\n    // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\n    if (this._interval.unref) {\n      // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\n      this._interval.unref();\n    }\n    this._flushShift = Math.floor(Math.random() * DEFAULT_FLUSH_INTERVAL / 1000);\n    this._forceFlush = false;\n  }\n\n  /**\n   * @inheritDoc\n   */\n  add(metricType, unsanitizedName, value) {\n    let unsanitizedUnit = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 'none';\n    let unsanitizedTags = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : {};\n    let maybeFloatTimestamp = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : timestampInSeconds();\n    const timestamp = Math.floor(maybeFloatTimestamp);\n    const name = sanitizeMetricKey(unsanitizedName);\n    const tags = sanitizeTags(unsanitizedTags);\n    const unit = sanitizeUnit(unsanitizedUnit);\n    const bucketKey = getBucketKey(metricType, name, unit, tags);\n    let bucketItem = this._buckets.get(bucketKey);\n    // If this is a set metric, we need to calculate the delta from the previous weight.\n    const previousWeight = bucketItem && metricType === SET_METRIC_TYPE ? bucketItem.metric.weight : 0;\n    if (bucketItem) {\n      bucketItem.metric.add(value);\n      // TODO(abhi): Do we need this check?\n      if (bucketItem.timestamp < timestamp) {\n        bucketItem.timestamp = timestamp;\n      }\n    } else {\n      bucketItem = {\n        // @ts-expect-error we don't need to narrow down the type of value here, saves bundle size.\n        metric: new METRIC_MAP[metricType](value),\n        timestamp,\n        metricType,\n        name,\n        unit,\n        tags\n      };\n      this._buckets.set(bucketKey, bucketItem);\n    }\n\n    // If value is a string, it's a set metric so calculate the delta from the previous weight.\n    const val = typeof value === 'string' ? bucketItem.metric.weight - previousWeight : value;\n    updateMetricSummaryOnActiveSpan(metricType, name, val, unit, unsanitizedTags, bucketKey);\n\n    // We need to keep track of the total weight of the buckets so that we can\n    // flush them when we exceed the max weight.\n    this._bucketsTotalWeight += bucketItem.metric.weight;\n    if (this._bucketsTotalWeight >= MAX_WEIGHT) {\n      this.flush();\n    }\n  }\n\n  /**\n   * Flushes the current metrics to the transport via the transport.\n   */\n  flush() {\n    this._forceFlush = true;\n    this._flush();\n  }\n\n  /**\n   * Shuts down metrics aggregator and clears all metrics.\n   */\n  close() {\n    this._forceFlush = true;\n    clearInterval(this._interval);\n    this._flush();\n  }\n\n  /**\n   * Flushes the buckets according to the internal state of the aggregator.\n   * If it is a force flush, which happens on shutdown, it will flush all buckets.\n   * Otherwise, it will only flush buckets that are older than the flush interval,\n   * and according to the flush shift.\n   *\n   * This function mutates `_forceFlush` and `_bucketsTotalWeight` properties.\n   */\n  _flush() {\n    // TODO(@anonrig): Add Atomics for locking to avoid having force flush and regular flush\n    // running at the same time.\n    // Ref: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Atomics\n\n    // This path eliminates the need for checking for timestamps since we're forcing a flush.\n    // Remember to reset the flag, or it will always flush all metrics.\n    if (this._forceFlush) {\n      this._forceFlush = false;\n      this._bucketsTotalWeight = 0;\n      this._captureMetrics(this._buckets);\n      this._buckets.clear();\n      return;\n    }\n    const cutoffSeconds = Math.floor(timestampInSeconds()) - DEFAULT_FLUSH_INTERVAL / 1000 - this._flushShift;\n    // TODO(@anonrig): Optimization opportunity.\n    // Convert this map to an array and store key in the bucketItem.\n    const flushedBuckets = new Map();\n    for (const [key, bucket] of this._buckets) {\n      if (bucket.timestamp <= cutoffSeconds) {\n        flushedBuckets.set(key, bucket);\n        this._bucketsTotalWeight -= bucket.metric.weight;\n      }\n    }\n    for (const [key] of flushedBuckets) {\n      this._buckets.delete(key);\n    }\n    this._captureMetrics(flushedBuckets);\n  }\n\n  /**\n   * Only captures a subset of the buckets passed to this function.\n   * @param flushedBuckets\n   */\n  _captureMetrics(flushedBuckets) {\n    if (flushedBuckets.size > 0 && this._client.captureAggregateMetrics) {\n      // TODO(@anonrig): Optimization opportunity.\n      // This copy operation can be avoided if we store the key in the bucketItem.\n      const buckets = Array.from(flushedBuckets).map(_ref => {\n        let [, bucketItem] = _ref;\n        return bucketItem;\n      });\n      this._client.captureAggregateMetrics(buckets);\n    }\n  }\n}\nexport { MetricsAggregator };","map":{"version":3,"names":["MetricsAggregator","constructor","_client","_buckets","Map","_bucketsTotalWeight","_interval","setInterval","_flush","DEFAULT_FLUSH_INTERVAL","unref","_flushShift","Math","floor","random","_forceFlush","add","metricType","unsanitizedName","value","unsanitizedUnit","arguments","length","undefined","unsanitizedTags","maybeFloatTimestamp","timestampInSeconds","timestamp","name","sanitizeMetricKey","tags","sanitizeTags","unit","sanitizeUnit","bucketKey","getBucketKey","bucketItem","get","previousWeight","SET_METRIC_TYPE","metric","weight","METRIC_MAP","set","val","updateMetricSummaryOnActiveSpan","MAX_WEIGHT","flush","close","clearInterval","_captureMetrics","clear","cutoffSeconds","flushedBuckets","key","bucket","delete","size","captureAggregateMetrics","buckets","Array","from","map","_ref"],"sources":["/Users/jeffreydebolt/Documents/fifo/cogs-dashboard/node_modules/@sentry/src/metrics/aggregator.ts"],"sourcesContent":["import type {\n  Client,\n  ClientOptions,\n  MeasurementUnit,\n  MetricsAggregator as MetricsAggregatorBase,\n  Primitive,\n} from '@sentry/types';\nimport { timestampInSeconds } from '@sentry/utils';\nimport { DEFAULT_FLUSH_INTERVAL, MAX_WEIGHT, SET_METRIC_TYPE } from './constants';\nimport { METRIC_MAP } from './instance';\nimport { updateMetricSummaryOnActiveSpan } from './metric-summary';\nimport type { MetricBucket, MetricType } from './types';\nimport { getBucketKey, sanitizeMetricKey, sanitizeTags, sanitizeUnit } from './utils';\n\n/**\n * A metrics aggregator that aggregates metrics in memory and flushes them periodically.\n */\nexport class MetricsAggregator implements MetricsAggregatorBase {\n  // TODO(@anonrig): Use FinalizationRegistry to have a proper way of flushing the buckets\n  // when the aggregator is garbage collected.\n  // Ref: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/FinalizationRegistry\n  private _buckets: MetricBucket;\n\n  // Different metrics have different weights. We use this to limit the number of metrics\n  // that we store in memory.\n  private _bucketsTotalWeight;\n\n  // Cast to any so that it can use Node.js timeout\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n  private readonly _interval: any;\n\n  // SDKs are required to shift the flush interval by random() * rollup_in_seconds.\n  // That shift is determined once per startup to create jittering.\n  private readonly _flushShift: number;\n\n  // An SDK is required to perform force flushing ahead of scheduled time if the memory\n  // pressure is too high. There is no rule for this other than that SDKs should be tracking\n  // abstract aggregation complexity (eg: a counter only carries a single float, whereas a\n  // distribution is a float per emission).\n  //\n  // Force flush is used on either shutdown, flush() or when we exceed the max weight.\n  private _forceFlush: boolean;\n\n  public constructor(private readonly _client: Client<ClientOptions>) {\n    this._buckets = new Map();\n    this._bucketsTotalWeight = 0;\n\n    this._interval = setInterval(() => this._flush(), DEFAULT_FLUSH_INTERVAL) as any;\n    // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\n    if (this._interval.unref) {\n      // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\n      this._interval.unref();\n    }\n\n    this._flushShift = Math.floor((Math.random() * DEFAULT_FLUSH_INTERVAL) / 1000);\n    this._forceFlush = false;\n  }\n\n  /**\n   * @inheritDoc\n   */\n  public add(\n    metricType: MetricType,\n    unsanitizedName: string,\n    value: number | string,\n    unsanitizedUnit: MeasurementUnit = 'none',\n    unsanitizedTags: Record<string, Primitive> = {},\n    maybeFloatTimestamp = timestampInSeconds(),\n  ): void {\n    const timestamp = Math.floor(maybeFloatTimestamp);\n    const name = sanitizeMetricKey(unsanitizedName);\n    const tags = sanitizeTags(unsanitizedTags);\n    const unit = sanitizeUnit(unsanitizedUnit as string);\n\n    const bucketKey = getBucketKey(metricType, name, unit, tags);\n\n    let bucketItem = this._buckets.get(bucketKey);\n    // If this is a set metric, we need to calculate the delta from the previous weight.\n    const previousWeight = bucketItem && metricType === SET_METRIC_TYPE ? bucketItem.metric.weight : 0;\n\n    if (bucketItem) {\n      bucketItem.metric.add(value);\n      // TODO(abhi): Do we need this check?\n      if (bucketItem.timestamp < timestamp) {\n        bucketItem.timestamp = timestamp;\n      }\n    } else {\n      bucketItem = {\n        // @ts-expect-error we don't need to narrow down the type of value here, saves bundle size.\n        metric: new METRIC_MAP[metricType](value),\n        timestamp,\n        metricType,\n        name,\n        unit,\n        tags,\n      };\n      this._buckets.set(bucketKey, bucketItem);\n    }\n\n    // If value is a string, it's a set metric so calculate the delta from the previous weight.\n    const val = typeof value === 'string' ? bucketItem.metric.weight - previousWeight : value;\n    updateMetricSummaryOnActiveSpan(metricType, name, val, unit, unsanitizedTags, bucketKey);\n\n    // We need to keep track of the total weight of the buckets so that we can\n    // flush them when we exceed the max weight.\n    this._bucketsTotalWeight += bucketItem.metric.weight;\n\n    if (this._bucketsTotalWeight >= MAX_WEIGHT) {\n      this.flush();\n    }\n  }\n\n  /**\n   * Flushes the current metrics to the transport via the transport.\n   */\n  public flush(): void {\n    this._forceFlush = true;\n    this._flush();\n  }\n\n  /**\n   * Shuts down metrics aggregator and clears all metrics.\n   */\n  public close(): void {\n    this._forceFlush = true;\n    clearInterval(this._interval);\n    this._flush();\n  }\n\n  /**\n   * Flushes the buckets according to the internal state of the aggregator.\n   * If it is a force flush, which happens on shutdown, it will flush all buckets.\n   * Otherwise, it will only flush buckets that are older than the flush interval,\n   * and according to the flush shift.\n   *\n   * This function mutates `_forceFlush` and `_bucketsTotalWeight` properties.\n   */\n  private _flush(): void {\n    // TODO(@anonrig): Add Atomics for locking to avoid having force flush and regular flush\n    // running at the same time.\n    // Ref: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Atomics\n\n    // This path eliminates the need for checking for timestamps since we're forcing a flush.\n    // Remember to reset the flag, or it will always flush all metrics.\n    if (this._forceFlush) {\n      this._forceFlush = false;\n      this._bucketsTotalWeight = 0;\n      this._captureMetrics(this._buckets);\n      this._buckets.clear();\n      return;\n    }\n    const cutoffSeconds = Math.floor(timestampInSeconds()) - DEFAULT_FLUSH_INTERVAL / 1000 - this._flushShift;\n    // TODO(@anonrig): Optimization opportunity.\n    // Convert this map to an array and store key in the bucketItem.\n    const flushedBuckets: MetricBucket = new Map();\n    for (const [key, bucket] of this._buckets) {\n      if (bucket.timestamp <= cutoffSeconds) {\n        flushedBuckets.set(key, bucket);\n        this._bucketsTotalWeight -= bucket.metric.weight;\n      }\n    }\n\n    for (const [key] of flushedBuckets) {\n      this._buckets.delete(key);\n    }\n\n    this._captureMetrics(flushedBuckets);\n  }\n\n  /**\n   * Only captures a subset of the buckets passed to this function.\n   * @param flushedBuckets\n   */\n  private _captureMetrics(flushedBuckets: MetricBucket): void {\n    if (flushedBuckets.size > 0 && this._client.captureAggregateMetrics) {\n      // TODO(@anonrig): Optimization opportunity.\n      // This copy operation can be avoided if we store the key in the bucketItem.\n      const buckets = Array.from(flushedBuckets).map(([, bucketItem]) => bucketItem);\n      this._client.captureAggregateMetrics(buckets);\n    }\n  }\n}\n"],"mappings":";;;;;;AAcA;AACA;AACA;AACO,MAAMA,iBAAA,CAAmD;EAChE;EACA;EACA;;EAGA;EACA;;EAGA;EACA;;EAGA;EACA;;EAGA;EACA;EACA;EACA;EACA;EACA;;EAGSC,WAAWA,CAAkBC,OAAO,EAAyB;IAAA,KAAAA,OAAA,GAAAA,OAAA;IAClE,IAAI,CAACC,QAAA,GAAW,IAAIC,GAAG,EAAE;IACzB,IAAI,CAACC,mBAAoB,GAAE,CAAC;IAE5B,IAAI,CAACC,SAAA,GAAYC,WAAW,CAAC,MAAM,IAAI,CAACC,MAAM,EAAE,EAAEC,sBAAsB,CAAE;IAC9E;IACI,IAAI,IAAI,CAACH,SAAS,CAACI,KAAK,EAAE;MAC9B;MACM,IAAI,CAACJ,SAAS,CAACI,KAAK,EAAE;IAC5B;IAEI,IAAI,CAACC,WAAA,GAAcC,IAAI,CAACC,KAAK,CAAED,IAAI,CAACE,MAAM,EAAG,GAAEL,sBAAsB,GAAI,IAAI,CAAC;IAC9E,IAAI,CAACM,WAAY,GAAE,KAAK;EAC5B;;EAEA;AACA;AACA;EACSC,GAAGA,CACRC,UAAU,EACVC,eAAe,EACfC,KAAK,EAIC;IAAA,IAHNC,eAAe,GAAAC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAoB,MAAM;IAAA,IACzCG,eAAe,GAAAH,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAA8B,EAAE;IAAA,IAC/CI,mBAAoB,GAAAJ,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAEK,kBAAkB,EAAE;IAE1C,MAAMC,SAAA,GAAYf,IAAI,CAACC,KAAK,CAACY,mBAAmB,CAAC;IACjD,MAAMG,IAAK,GAAEC,iBAAiB,CAACX,eAAe,CAAC;IAC/C,MAAMY,IAAK,GAAEC,YAAY,CAACP,eAAe,CAAC;IAC1C,MAAMQ,IAAK,GAAEC,YAAY,CAACb,eAAA,CAA0B;IAEpD,MAAMc,SAAA,GAAYC,YAAY,CAAClB,UAAU,EAAEW,IAAI,EAAEI,IAAI,EAAEF,IAAI,CAAC;IAE5D,IAAIM,UAAW,GAAE,IAAI,CAACjC,QAAQ,CAACkC,GAAG,CAACH,SAAS,CAAC;IACjD;IACI,MAAMI,cAAA,GAAiBF,UAAA,IAAcnB,UAAW,KAAIsB,eAAgB,GAAEH,UAAU,CAACI,MAAM,CAACC,MAAA,GAAS,CAAC;IAElG,IAAIL,UAAU,EAAE;MACdA,UAAU,CAACI,MAAM,CAACxB,GAAG,CAACG,KAAK,CAAC;MAClC;MACM,IAAIiB,UAAU,CAACT,SAAU,GAAEA,SAAS,EAAE;QACpCS,UAAU,CAACT,SAAU,GAAEA,SAAS;MACxC;IACA,OAAW;MACLS,UAAA,GAAa;QACnB;QACQI,MAAM,EAAE,IAAIE,UAAU,CAACzB,UAAU,CAAC,CAACE,KAAK,CAAC;QACzCQ,SAAS;QACTV,UAAU;QACVW,IAAI;QACJI,IAAI;QACJF;MACR,CAAO;MACD,IAAI,CAAC3B,QAAQ,CAACwC,GAAG,CAACT,SAAS,EAAEE,UAAU,CAAC;IAC9C;;IAEA;IACI,MAAMQ,GAAI,GAAE,OAAOzB,KAAA,KAAU,QAAS,GAAEiB,UAAU,CAACI,MAAM,CAACC,MAAA,GAASH,cAAA,GAAiBnB,KAAK;IACzF0B,+BAA+B,CAAC5B,UAAU,EAAEW,IAAI,EAAEgB,GAAG,EAAEZ,IAAI,EAAER,eAAe,EAAEU,SAAS,CAAC;;IAE5F;IACA;IACI,IAAI,CAAC7B,mBAAoB,IAAG+B,UAAU,CAACI,MAAM,CAACC,MAAM;IAEpD,IAAI,IAAI,CAACpC,mBAAoB,IAAGyC,UAAU,EAAE;MAC1C,IAAI,CAACC,KAAK,EAAE;IAClB;EACA;;EAEA;AACA;AACA;EACSA,KAAKA,CAAA,EAAS;IACnB,IAAI,CAAChC,WAAY,GAAE,IAAI;IACvB,IAAI,CAACP,MAAM,EAAE;EACjB;;EAEA;AACA;AACA;EACSwC,KAAKA,CAAA,EAAS;IACnB,IAAI,CAACjC,WAAY,GAAE,IAAI;IACvBkC,aAAa,CAAC,IAAI,CAAC3C,SAAS,CAAC;IAC7B,IAAI,CAACE,MAAM,EAAE;EACjB;;EAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACUA,MAAMA,CAAA,EAAS;IACzB;IACA;IACA;;IAEA;IACA;IACI,IAAI,IAAI,CAACO,WAAW,EAAE;MACpB,IAAI,CAACA,WAAY,GAAE,KAAK;MACxB,IAAI,CAACV,mBAAoB,GAAE,CAAC;MAC5B,IAAI,CAAC6C,eAAe,CAAC,IAAI,CAAC/C,QAAQ,CAAC;MACnC,IAAI,CAACA,QAAQ,CAACgD,KAAK,EAAE;MACrB;IACN;IACI,MAAMC,aAAc,GAAExC,IAAI,CAACC,KAAK,CAACa,kBAAkB,EAAE,IAAIjB,sBAAuB,GAAE,OAAO,IAAI,CAACE,WAAW;IAC7G;IACA;IACI,MAAM0C,cAAc,GAAiB,IAAIjD,GAAG,EAAE;IAC9C,KAAK,MAAM,CAACkD,GAAG,EAAEC,MAAM,KAAK,IAAI,CAACpD,QAAQ,EAAE;MACzC,IAAIoD,MAAM,CAAC5B,SAAU,IAAGyB,aAAa,EAAE;QACrCC,cAAc,CAACV,GAAG,CAACW,GAAG,EAAEC,MAAM,CAAC;QAC/B,IAAI,CAAClD,mBAAoB,IAAGkD,MAAM,CAACf,MAAM,CAACC,MAAM;MACxD;IACA;IAEI,KAAK,MAAM,CAACa,GAAG,CAAE,IAAGD,cAAc,EAAE;MAClC,IAAI,CAAClD,QAAQ,CAACqD,MAAM,CAACF,GAAG,CAAC;IAC/B;IAEI,IAAI,CAACJ,eAAe,CAACG,cAAc,CAAC;EACxC;;EAEA;AACA;AACA;AACA;EACUH,eAAeA,CAACG,cAAc,EAAsB;IAC1D,IAAIA,cAAc,CAACI,IAAK,GAAE,CAAE,IAAG,IAAI,CAACvD,OAAO,CAACwD,uBAAuB,EAAE;MACzE;MACA;MACM,MAAMC,OAAA,GAAUC,KAAK,CAACC,IAAI,CAACR,cAAc,CAAC,CAACS,GAAG,CAACC,IAAA;QAAA,IAAC,GAAG3B,UAAU,CAAC,GAAA2B,IAAA;QAAA,OAAK3B,UAAU;MAAA,EAAC;MAC9E,IAAI,CAAClC,OAAO,CAACwD,uBAAuB,CAACC,OAAO,CAAC;IACnD;EACA;AACA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}