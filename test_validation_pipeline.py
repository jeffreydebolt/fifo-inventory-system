#!/usr/bin/env python3
"""
Comprehensive test script for the intelligent upload validation pipeline.
Demonstrates handling of messy real-world data formats.
"""

import pandas as pd
import sys
import os
from pathlib import Path

# Add the project root to Python path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from services.format_detector import FormatDetector
from services.upload_validator import UploadValidator
from services.data_preview import DataPreviewService
from services.quarantine_manager import QuarantineManager


def test_file(file_path: str, file_description: str):
    """Test a single file through the complete validation pipeline"""
    print("=" * 80)
    print(f"TESTING: {file_description}")
    print(f"FILE: {file_path}")
    print("=" * 80)
    
    try:
        # Load the CSV file
        df = pd.read_csv(file_path)
        print(f"‚úÖ Loaded CSV with {len(df)} rows and {len(df.columns)} columns")
        
        # Step 1: Format Detection
        print("\nüîç STEP 1: FORMAT DETECTION")
        print("-" * 40)
        
        detector = FormatDetector()
        detection_result = detector.detect_format(df)
        
        print(f"Detected File Type: {detection_result.file_type.value}")
        print(f"Detection Confidence: {detection_result.confidence:.2%}")
        print(f"Detected {len(detection_result.columns)} columns:")
        
        for col_name, col_info in detection_result.columns.items():
            print(f"  - {col_info.original_name}: {col_info.data_type.__name__}")
            if col_info.format_type:
                print(f"    Format: {col_info.format_type}")
            if col_info.issues:
                print(f"    Issues: {', '.join(col_info.issues)}")
        
        if detection_result.recommendations:
            print("\nRecommendations:")
            for rec in detection_result.recommendations:
                print(f"  üí° {rec}")
        
        # Suggest column mapping
        suggested_mapping = detector.suggest_column_mapping(detection_result)
        if suggested_mapping:
            print("\nSuggested Column Mapping:")
            for standard, detected in suggested_mapping.items():
                print(f"  {standard} -> {detected}")
        
        # Step 2: Data Validation
        print("\n‚úÖ STEP 2: DATA VALIDATION")
        print("-" * 40)
        
        validator = UploadValidator()
        
        if detection_result.file_type.value == "sales_data":
            validation_result = validator.validate_sales_data(df)
        elif detection_result.file_type.value == "lots_data":
            validation_result = validator.validate_lots_data(df)
        else:
            print("‚ö†Ô∏è Unknown file type - attempting sales data validation")
            validation_result = validator.validate_sales_data(df)
        
        print(f"Total rows: {validation_result.summary.get('total_rows', 0)}")
        print(f"Processable rows: {validation_result.processable_rows}")
        print(f"Quarantined rows: {validation_result.quarantined_rows}")
        print(f"Success rate: {validation_result.processable_rows / validation_result.summary.get('total_rows', 1):.1%}")
        
        # Show validation issues
        if validation_result.issues:
            print(f"\nValidation Issues ({len(validation_result.issues)}):")
            issue_counts = {}
            for issue in validation_result.issues:
                severity = issue.severity.value
                issue_counts[severity] = issue_counts.get(severity, 0) + 1
            
            for severity, count in issue_counts.items():
                print(f"  {severity.upper()}: {count}")
            
            # Show sample issues
            print("\nSample Issues:")
            for i, issue in enumerate(validation_result.issues[:5]):
                print(f"  {i+1}. Row {issue.row_index}, {issue.column}: {issue.message}")
            
            if len(validation_result.issues) > 5:
                print(f"  ... and {len(validation_result.issues) - 5} more issues")
        
        # Step 3: Data Preview
        print("\nüìã STEP 3: DATA PREVIEW")
        print("-" * 40)
        
        preview_service = DataPreviewService()
        preview = preview_service.create_preview(
            detection_result, 
            validation_result,
            os.path.basename(file_path)
        )
        
        print(f"Preview Status: {preview.status.value}")
        print(f"Safe to Import: {'Yes' if preview.is_safe_to_import else 'No'}")
        print(f"Requires Review: {'Yes' if preview.requires_manual_review else 'No'}")
        
        # Show actionable steps
        actions = preview_service.get_actionable_steps(preview)
        if actions:
            print("\nActionable Steps:")
            for i, action in enumerate(actions, 1):
                print(f"  {i}. {action['title']}: {action['description']}")
        
        # Step 4: Quarantine Management (if needed)
        if validation_result.quarantined_rows > 0:
            print("\nüè• STEP 4: QUARANTINE MANAGEMENT")
            print("-" * 40)
            
            quarantine_manager = QuarantineManager()
            batch = quarantine_manager.quarantine_data(
                validation_result,
                os.path.basename(file_path),
                detection_result.file_type.value
            )
            
            print(f"Created quarantine batch: {batch.batch_id}")
            print(f"Quarantined {batch.quarantined_count} records")
            print(f"Quarantine rate: {batch.quarantine_rate:.1%}")
            
            # Show quarantine reasons
            reason_counts = {}
            for record in batch.records:
                reason = record.quarantine_reason.value
                reason_counts[reason] = reason_counts.get(reason, 0) + 1
            
            print("\nQuarantine Reasons:")
            for reason, count in reason_counts.items():
                print(f"  {reason}: {count}")
            
            # Export quarantine data for manual review
            export_path = quarantine_manager.export_quarantine_csv(batch.batch_id)
            if export_path:
                print(f"üìÅ Exported quarantine data to: {export_path}")
        
        # Generate comprehensive preview report
        print("\nüìä COMPREHENSIVE PREVIEW REPORT")
        print("-" * 40)
        report = preview_service.generate_preview_report(preview)
        print(report)
        
    except Exception as e:
        print(f"‚ùå ERROR processing {file_path}: {str(e)}")
        import traceback
        traceback.print_exc()
    
    print("\n")


def main():
    """Run tests on all sample data files"""
    print("üöÄ INTELLIGENT UPLOAD VALIDATION PIPELINE TEST")
    print("Testing real-world messy data scenarios")
    print()
    
    # Create test data directory if it doesn't exist
    test_data_dir = Path("test_data")
    
    # Test files with descriptions
    test_files = [
        ("test_data/messy_sales_data.csv", "Messy Sales Data - Mixed formats, missing values, invalid data"),
        ("test_data/messy_lots_data.csv", "Messy Lots Data - Currency formats, scientific notation, bad dates"),
        ("test_data/excel_export_issues.csv", "Excel Export Issues - Formulas, booleans, serial dates"),
        ("test_data/mixed_formats.csv", "Mixed Formats - Various date and number formats"),
    ]
    
    # Also test with existing real data files
    real_files = [
        ("sales_data.csv", "Real Sales Data - Current format"),
        ("lots_to_upload.csv", "Real Lots Data - Current format"),
    ]
    
    all_files = test_files + [(f, f"Real data: {desc}") for f, desc in real_files if os.path.exists(f)]
    
    # Run tests
    for file_path, description in all_files:
        if os.path.exists(file_path):
            test_file(file_path, description)
        else:
            print(f"‚ö†Ô∏è Skipping {file_path} - file not found")
    
    print("‚úÖ TESTING COMPLETE")
    print("\nSUMMARY:")
    print("The intelligent upload system successfully:")
    print("- Detects file formats and column structures automatically")
    print("- Handles messy real-world data gracefully without failing")
    print("- Quarantines problematic data for manual review")
    print("- Provides clear feedback and actionable recommendations")
    print("- Never loses data - everything is preserved for review")
    

if __name__ == "__main__":
    main()